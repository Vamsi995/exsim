{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4f6c13a6fce547539bea28a30b9bda1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9668277046b483591be0b23d5704311",
              "IPY_MODEL_bcfea3511c944f629d6ae28d65e24856",
              "IPY_MODEL_1138e1484a114e138387e5f018b720d7"
            ],
            "layout": "IPY_MODEL_db73536639884372a29a0f6651e4b494"
          }
        },
        "b9668277046b483591be0b23d5704311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b0aaaaa11f74f608ae8e370895fc526",
            "placeholder": "​",
            "style": "IPY_MODEL_a4ce757a5087437b84b08c78b7ed39f5",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "bcfea3511c944f629d6ae28d65e24856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5360a5bdcc44493a7d31c8567735175",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77db20c0d18548eab3a6da8a67827e75",
            "value": 8
          }
        },
        "1138e1484a114e138387e5f018b720d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e0727c41c3548edab51b35e93b3002b",
            "placeholder": "​",
            "style": "IPY_MODEL_d07d1f8612c64ec29470157ba537f2c8",
            "value": " 8/8 [00:10&lt;00:00,  1.10s/it]"
          }
        },
        "db73536639884372a29a0f6651e4b494": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b0aaaaa11f74f608ae8e370895fc526": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4ce757a5087437b84b08c78b7ed39f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5360a5bdcc44493a7d31c8567735175": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77db20c0d18548eab3a6da8a67827e75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e0727c41c3548edab51b35e93b3002b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d07d1f8612c64ec29470157ba537f2c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q accelerate safetensors"
      ],
      "metadata": {
        "id": "tZlsE84oppZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "vJ4kle-5ptT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Colab-Ready Notebook: Functional Similarity Testing for MoE Experts (Decoder-Only)\n",
        "\n",
        "\n",
        "\n",
        "# Load Qwen1.5-MoE decoder-only model\n",
        "model_id = \"Qwen/Qwen1.5-MoE-A2.7B\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4f6c13a6fce547539bea28a30b9bda1a",
            "b9668277046b483591be0b23d5704311",
            "bcfea3511c944f629d6ae28d65e24856",
            "1138e1484a114e138387e5f018b720d7",
            "db73536639884372a29a0f6651e4b494",
            "0b0aaaaa11f74f608ae8e370895fc526",
            "a4ce757a5087437b84b08c78b7ed39f5",
            "a5360a5bdcc44493a7d31c8567735175",
            "77db20c0d18548eab3a6da8a67827e75",
            "4e0727c41c3548edab51b35e93b3002b",
            "d07d1f8612c64ec29470157ba537f2c8"
          ]
        },
        "id": "jyt9Tyi0pvEV",
        "outputId": "306531a0-b218-43f4-fe61-23bdbf01d850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f6c13a6fce547539bea28a30b9bda1a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "pKdVPEL3Wpqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u5in3R8Wrsq",
        "outputId": "c2a40bd1-d81e-4848-de7b-349be873bbbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.32.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "NoPGQjW2WwFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
        "\n",
        "def tokenize(example):\n",
        "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "tok_ds = dataset[\"train\"].map(tokenize, batched=True, remove_columns=[\"text\"])\n",
        "train_size = int(0.8 * len(tok_ds))\n",
        "train_ds, val_ds = random_split(tok_ds, [train_size, len(tok_ds) - train_size])\n",
        "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=8)\n"
      ],
      "metadata": {
        "id": "RIwUnQpLWu8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Code"
      ],
      "metadata": {
        "id": "kmxyaLtXSLzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from collections import defaultdict\n"
      ],
      "metadata": {
        "id": "HmAFwfakSPj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -------------------\n",
        "# Adapter Definition\n",
        "# -------------------\n",
        "class Adapter(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(dim, dim)\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.norm(self.linear(x))"
      ],
      "metadata": {
        "id": "uAgx1cA68oBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "\n",
        "# Captures (input, output) for each expert\n",
        "expert_pairs = defaultdict(list)\n",
        "\n",
        "def make_aligned_expert_hook(layer_id, expert_id):\n",
        "    def hook_fn(module, input, output):\n",
        "        z1 = input[0].detach().cpu()\n",
        "        fz1 = output.detach().cpu()\n",
        "        for i in range(z1.shape[0]):\n",
        "            expert_pairs[(layer_id, expert_id)].append((z1[i], fz1[i]))\n",
        "    return hook_fn\n",
        "\n",
        "# def get_aligned_data(layer_id, expert_id, device):\n",
        "#     z_list, fz_list = zip(*expert_pairs[(layer_id, expert_id)])\n",
        "#     z1 = torch.stack(z_list).to(device)\n",
        "#     fz1 = torch.stack(fz_list).to(device)\n",
        "#     return z1, fz1\n",
        "\n",
        "def get_aligned_data(layer_id, expert_id, device, max_samples=None):\n",
        "    z_list, fz_list = zip(*expert_pairs[(layer_id, expert_id)])\n",
        "    if max_samples is not None:\n",
        "        z_list = z_list[:max_samples]\n",
        "        fz_list = fz_list[:max_samples]\n",
        "    z1 = torch.stack(z_list).to(device)\n",
        "    fz1 = torch.stack(fz_list).to(device)\n",
        "    return z1, fz1\n",
        "\n",
        "\n",
        "# This captures the input before routing\n",
        "layer_inputs = defaultdict(list)\n",
        "def make_router_input_hook(layer_id):\n",
        "    def hook_fn(module, input):\n",
        "        hidden = input[0]\n",
        "        if hidden.size(-1) == 2048:\n",
        "            layer_inputs[layer_id].append(hidden.detach().cpu())\n",
        "    return hook_fn\n",
        "\n",
        "# Attach hooks for two experts at (layer1, expert1) and (layer2, expert2)\n",
        "def attach_moe_hooks(model, pair1, pair2):\n",
        "    hooks = []\n",
        "    for lid in {pair1[0], pair2[0]}:\n",
        "        moe_block = model.model.layers[lid].mlp\n",
        "        hooks.append(moe_block.register_forward_pre_hook(make_router_input_hook(lid)))\n",
        "    for (lid, eid) in [pair1, pair2]:\n",
        "        expert = model.model.layers[lid].mlp.experts[eid]\n",
        "        hooks.append(expert.register_forward_hook(make_aligned_expert_hook(lid, eid)))\n",
        "    return hooks\n",
        "\n",
        "\n",
        "# Manually run z1 through expert1 to get f1_output\n",
        "def get_z1_and_f1_output(layer_id, expert_id, device):\n",
        "    z1 = torch.cat(layer_inputs[layer_id], dim=0).to(device)\n",
        "    expert = model.model.layers[layer_id].mlp.experts[expert_id]\n",
        "    f1_output = expert(z1)\n",
        "    return z1, f1_output\n",
        "\n"
      ],
      "metadata": {
        "id": "zrC9ZHUDSLf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for h in hooks: h.remove()"
      ],
      "metadata": {
        "id": "hPfITCOFZaNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------\n",
        "# Run Inference + Compare Experts\n",
        "# -------------------\n",
        "layer1, expert1 = 1, 1\n",
        "layer2, expert2 = 2, 0\n",
        "hooks = attach_moe_hooks(model, (layer1, expert1), (layer2, expert2))"
      ],
      "metadata": {
        "id": "piazgxWXUGJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "samples_needed = 20000\n",
        "with torch.no_grad():\n",
        "    for batch in train_loader:\n",
        "        input_ids = torch.stack(batch['input_ids']).to('cuda')\n",
        "        model(input_ids)\n",
        "        if len(expert_pairs[(layer1, expert1)]) >= samples_needed:\n",
        "            break\n",
        "for h in hooks: h.remove()\n",
        "\n"
      ],
      "metadata": {
        "id": "rd28-HXMXJsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z1, f1_out = get_aligned_data(layer1, expert1, model.device)\n",
        "f2 = model.model.layers[layer2].mlp.experts[expert2]"
      ],
      "metadata": {
        "id": "VuGyrLSsXnWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_adapter_aligning_experts(y1, f1_output, f2, lr=1e-3, steps=10):\n",
        "    adapter = Adapter(y1.size(-1)).to(y1.device).train()\n",
        "    opt = torch.optim.Adam(adapter.parameters(), lr=lr)\n",
        "\n",
        "    y1 = y1.to(torch.float32)\n",
        "    f1_output = f1_output.to(torch.float32)\n",
        "    f2 = f2.to(torch.float32)\n",
        "    # adapter = adapter.to(torch.float32)\n",
        "\n",
        "    for _ in range(steps):\n",
        "\n",
        "        aligned_input = adapter(y1)\n",
        "      # with torch.no_grad(): # Wrap the call to f2 with no_grad\n",
        "        f2_output = f2(aligned_input)\n",
        "        # f2_output.to(torch.float32)\n",
        "        # f2_output = f2(aligned_input\n",
        "\n",
        "        # f2_output = f2(aligned_input)\n",
        "        if torch.isnan(f2_output).any():\n",
        "          print(\"❌ NaNs in f2_output\")\n",
        "          break\n",
        "        if torch.isnan(f1_output).any():\n",
        "            print(\"❌ NaNs in f1_output\")\n",
        "            break\n",
        "        if f2_output.ndim == 3:\n",
        "            f2_output = f2_output.view(-1, f2_output.size(-1))\n",
        "        if f1_output.ndim == 3:\n",
        "            f1_output = f1_output.view(-1, f1_output.size(-1))\n",
        "\n",
        "        loss = F.mse_loss(f2_output, f1_output)\n",
        "        opt.zero_grad()\n",
        "        loss.backward(retain_graph=True)\n",
        "        opt.step()\n",
        "\n",
        "    # print(loss.detach().item())\n",
        "\n",
        "    f2 = f2.to(torch.float16)\n",
        "    print(loss.item())\n",
        "    return adapter, loss.item()"
      ],
      "metadata": {
        "id": "3P87N_Ui30id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adapter, loss = train_adapter_aligning_experts(z1, f1_out, f2)\n",
        "print(f\"✅ Final Adapter MSE Loss: {loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uomGT2NXl5a",
        "outputId": "2aeb0756-444a-498b-8eb1-a6e55ecc8ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.24927015602588654\n",
            "0.050167590379714966\n",
            "0.037436481565237045\n",
            "0.027257481589913368\n",
            "0.02222025953233242\n",
            "0.01993030495941639\n",
            "0.01888357847929001\n",
            "0.01834593527019024\n",
            "0.0180082768201828\n",
            "0.017751488834619522\n",
            "✅ Final Adapter MSE Loss: 0.0178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# text = \"The economy is improving and markets are responding positively.\"\n",
        "# inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "# print(inputs)\n",
        "# with torch.no_grad():\n",
        "#     _ = model(**inputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48tyiastUDx5",
        "outputId": "2a4e0d1c-f2da-46fe-adf0-d3b6f482096f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  785,  8584,   374, 18392,   323, 11725,   525, 29338, 39546,    13]],\n",
            "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Gather data\n",
        "# y1 = torch.cat(layer_inputs[layer1], dim=0).to(\"cuda\")\n",
        "# f1_output = torch.cat(expert_outputs[(layer1, expert1)], dim=0).to(\"cuda\")\n",
        "\n",
        "# y1, f1_output = get_z1_and_f1_output(layer1, expert1, device=\"cuda\")\n",
        "# f2 = model.model.layers[layer2].mlp.experts[expert2]\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "cpALbHdvUB75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train adapter: f2(A(y1)) ≈ f1(z1)\n",
        "adapter, loss = train_adapter_aligning_experts(y1, f1_output, f2)\n",
        "print(f\"✅ Final Adapter MSE Loss (f2(A(y1)) ≈ f1(z1)): {loss:.6f}\")\n",
        "\n",
        "# Cleanup\n",
        "for h in hooks:\n",
        "    h.remove()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lHG9OGIL33s8",
        "outputId": "d8e8e50d-158d-4423-f53d-b0ed49e4e28e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.09067047387361526\n",
            "38.54270553588867\n",
            "0.20621776580810547\n",
            "0.14524886012077332\n",
            "0.09172222763299942\n",
            "0.061609137803316116\n",
            "0.0469362847507\n",
            "0.03986551612615585\n",
            "0.03613929823040962\n",
            "0.03386891633272171\n",
            "0.03226346895098686\n",
            "0.030997002497315407\n",
            "0.029936401173472404\n",
            "0.029026532545685768\n",
            "0.028242135420441628\n",
            "0.027567831799387932\n",
            "0.02699037455022335\n",
            "0.02649623155593872\n",
            "0.026071518659591675\n",
            "0.02570287697017193\n",
            "0.02537832036614418\n",
            "0.025087663903832436\n",
            "0.024822819977998734\n",
            "0.02457754872739315\n",
            "0.0243472121655941\n",
            "0.024128450080752373\n",
            "0.023918839171528816\n",
            "0.023716680705547333\n",
            "0.02352074719965458\n",
            "0.023330166935920715\n",
            "0.023144308477640152\n",
            "0.022962680086493492\n",
            "0.022784942761063576\n",
            "0.02261078916490078\n",
            "0.02243999019265175\n",
            "0.022272348403930664\n",
            "0.022107703611254692\n",
            "0.021945904940366745\n",
            "0.021786827594041824\n",
            "0.021630359813570976\n",
            "0.021476412191987038\n",
            "0.021324878558516502\n",
            "0.02117571048438549\n",
            "0.02102884091436863\n",
            "0.020884212106466293\n",
            "0.02074178121984005\n",
            "0.020601525902748108\n",
            "0.020463405176997185\n",
            "0.020327381789684296\n",
            "0.02019345387816429\n",
            "0.02006157487630844\n",
            "0.019931718707084656\n",
            "0.0198038499802351\n",
            "0.019677942618727684\n",
            "0.01955391839146614\n",
            "0.019431738182902336\n",
            "0.019311338663101196\n",
            "0.019192641600966454\n",
            "0.019075557589530945\n",
            "0.018960008397698402\n",
            "0.01884591020643711\n",
            "0.01873316802084446\n",
            "0.018621688708662987\n",
            "0.01851140335202217\n",
            "0.018402226269245148\n",
            "0.018294084817171097\n",
            "0.018186932429671288\n",
            "0.018080715090036392\n",
            "0.01797538995742798\n",
            "0.01787092350423336\n",
            "0.017767304554581642\n",
            "0.01766449771821499\n",
            "0.01756250113248825\n",
            "0.017461299896240234\n",
            "0.017360884696245193\n",
            "0.017261242493987083\n",
            "0.01716236211359501\n",
            "0.017064237967133522\n",
            "0.016966847702860832\n",
            "0.016870196908712387\n",
            "0.0167742520570755\n",
            "0.016679007560014725\n",
            "0.01658443920314312\n",
            "0.016490543261170387\n",
            "0.016397297382354736\n",
            "0.01630469039082527\n",
            "0.016212699934840202\n",
            "0.016121331602334976\n",
            "0.016030553728342056\n",
            "0.015940358862280846\n",
            "0.015850750729441643\n",
            "0.015761716291308403\n",
            "0.015673238784074783\n",
            "0.015585317276418209\n",
            "0.015497945249080658\n",
            "0.015411111526191235\n",
            "0.015324823558330536\n",
            "0.015239061787724495\n",
            "0.01515383180230856\n",
            "0.01506912149488926\n",
            "0.014984932728111744\n",
            "0.014901257120072842\n",
            "0.014818089082837105\n",
            "0.014735427685081959\n",
            "0.01465326827019453\n",
            "0.014571607112884521\n",
            "0.014490440487861633\n",
            "0.014409765601158142\n",
            "0.014329581521451473\n",
            "0.014249876141548157\n",
            "0.014170658774673939\n",
            "0.014091921038925648\n",
            "0.014013664796948433\n",
            "0.013935886323451996\n",
            "0.013858586549758911\n",
            "0.013781762681901455\n",
            "0.013705414719879627\n",
            "0.013629542663693428\n",
            "0.013554150238633156\n",
            "0.013479228131473064\n",
            "0.01340478379279375\n",
            "0.013330823741853237\n",
            "0.013257332146167755\n",
            "0.013184323906898499\n",
            "0.013111799024045467\n",
            "0.013039745390415192\n",
            "0.012968184426426888\n",
            "0.012897098436951637\n",
            "0.012826497666537762\n",
            "0.01275638397783041\n",
            "0.012686756439507008\n",
            "0.012617615051567554\n",
            "0.012548960745334625\n",
            "0.012480797246098518\n",
            "0.012413120828568935\n",
            "0.012345932424068451\n",
            "0.012279234826564789\n",
            "0.012213029898703098\n",
            "0.012147309258580208\n",
            "0.012082080356776714\n",
            "0.012017334811389446\n",
            "0.011953077279031277\n",
            "0.011889304034411907\n",
            "0.011826015077531338\n",
            "0.011763202957808971\n",
            "0.01170087605714798\n",
            "0.011639023199677467\n",
            "0.01157764345407486\n",
            "0.011516733095049858\n",
            "0.011456298641860485\n",
            "0.011396326124668121\n",
            "0.011336821131408215\n",
            "0.011277773417532444\n",
            "0.011219183914363384\n",
            "0.011161052621901035\n",
            "0.011103371158242226\n",
            "0.01104613859206438\n",
            "0.010989349335432053\n",
            "0.010933006182312965\n",
            "0.010877100750803947\n",
            "0.010821630246937275\n",
            "0.01076659094542265\n",
            "0.01071198284626007\n",
            "0.010657806880772114\n",
            "0.01060404907912016\n",
            "0.01055071223527193\n",
            "0.01049779262393713\n",
            "0.010445287451148033\n",
            "0.010393192991614342\n",
            "0.010341506451368332\n",
            "0.01029022317379713\n",
            "0.010239344090223312\n",
            "0.01018886175006628\n",
            "0.01013877522200346\n",
            "0.010089082643389702\n",
            "0.010039778426289558\n",
            "0.009990865364670753\n",
            "0.009942333213984966\n",
            "0.009894183836877346\n",
            "0.009846409782767296\n",
            "0.00979901384562254\n",
            "0.009751989506185055\n",
            "0.009705333039164543\n",
            "0.009659048169851303\n",
            "0.009613129310309887\n",
            "0.009567566215991974\n",
            "0.009522363543510437\n",
            "0.009477520361542702\n",
            "0.009433026425540447\n",
            "0.009388885460793972\n",
            "0.009345093742012978\n",
            "0.009301644749939442\n",
            "0.009258543141186237\n",
            "0.009215778671205044\n",
            "0.00917335320264101\n",
            "0.009131262078881264\n",
            "0.009089503437280655\n",
            "0.00904807448387146\n",
            "0.009006974287331104\n",
            "0.008966198191046715\n",
            "0.008925745263695717\n",
            "0.008885608986020088\n",
            "0.008845791220664978\n",
            "0.008806290104985237\n",
            "0.008767098188400269\n",
            "0.008728216402232647\n",
            "0.008689643815159798\n",
            "0.008651375770568848\n",
            "0.008613409474492073\n",
            "0.00857574213296175\n",
            "0.008538372814655304\n",
            "0.008501299656927586\n",
            "0.008464518003165722\n",
            "0.008428026922047138\n",
            "0.008391824550926685\n",
            "0.00835590809583664\n",
            "0.008320273831486702\n",
            "0.008284921757876873\n",
            "0.008249848149716854\n",
            "0.00821505207568407\n",
            "0.008180530741810799\n",
            "0.00814628042280674\n",
            "0.00811230018734932\n",
            "0.008078587241470814\n",
            "0.008045139722526073\n",
            "0.0080119539052248\n",
            "0.007979034446179867\n",
            "0.007946369238197803\n",
            "0.007913962006568909\n",
            "0.007881809957325459\n",
            "0.00784991029649973\n",
            "0.007818261161446571\n",
            "0.007786862086504698\n",
            "0.007755707483738661\n",
            "0.007724796887487173\n",
            "0.007694128900766373\n",
            "0.007663703989237547\n",
            "0.007633514702320099\n",
            "0.007603564765304327\n",
            "0.007573847658932209\n",
            "0.007544361986219883\n",
            "0.007515107747167349\n",
            "0.007486081216484308\n",
            "0.007457282394170761\n",
            "0.007428710348904133\n",
            "0.0074003576301038265\n",
            "0.007372228894382715\n",
            "0.007344316691160202\n",
            "0.007316623814404011\n",
            "0.007289146538823843\n",
            "0.0072618811391294\n",
            "0.007234829943627119\n",
            "0.007207989227026701\n",
            "0.007181353867053986\n",
            "0.007154928054660559\n",
            "0.00712870666757226\n",
            "0.007102688308805227\n",
            "0.007076870184391737\n",
            "0.007051253225654364\n",
            "0.007025833707302809\n",
            "0.0070006088353693485\n",
            "0.006975581403821707\n",
            "0.006950744893401861\n",
            "0.006926100701093674\n",
            "0.006901645567268133\n",
            "0.006877378560602665\n",
            "0.0068532987497746944\n",
            "0.006829403340816498\n",
            "0.006805692799389362\n",
            "0.006782160606235266\n",
            "0.0067588104866445065\n",
            "0.006735639180988073\n",
            "0.006712643895298243\n",
            "0.006689824163913727\n",
            "0.0066671790555119514\n",
            "0.006644705776125193\n",
            "0.006622403860092163\n",
            "0.006600269582122564\n",
            "0.0065783048048615456\n",
            "0.006556508131325245\n",
            "0.006534875370562077\n",
            "0.006513405125588179\n",
            "0.006492097862064838\n",
            "0.006470949854701757\n",
            "0.006449962500482798\n",
            "0.006429133005440235\n",
            "0.006408459972590208\n",
            "0.006387942470610142\n",
            "0.006367578636854887\n",
            "0.00634736567735672\n",
            "0.0063273049890995026\n",
            "0.006307393312454224\n",
            "0.006287630181759596\n",
            "0.006268014200031757\n",
            "0.0062485444359481335\n",
            "0.006229219026863575\n",
            "0.00621003657579422\n",
            "0.006190996617078781\n",
            "0.006172094494104385\n",
            "0.006153335329145193\n",
            "✅ Final Adapter MSE Loss (f2(A(y1)) ≈ f1(z1)): 0.006153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for h in hooks:\n",
        "  h.remove()"
      ],
      "metadata": {
        "id": "Z0-Gt0FBR6_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVPeHsiPSSdq",
        "outputId": "d29711d6-43af-42fc-99c7-871f30880033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Qwen2MoeForCausalLM(\n",
              "  (model): Qwen2MoeModel(\n",
              "    (embed_tokens): Embedding(151936, 2048)\n",
              "    (layers): ModuleList(\n",
              "      (0-23): 24 x Qwen2MoeDecoderLayer(\n",
              "        (self_attn): Qwen2MoeSdpaAttention(\n",
              "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "          (rotary_emb): Qwen2MoeRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen2MoeSparseMoeBlock(\n",
              "          (gate): Linear(in_features=2048, out_features=60, bias=False)\n",
              "          (experts): ModuleList(\n",
              "            (0-59): 60 x Qwen2MoeMLP(\n",
              "              (gate_proj): Linear(in_features=2048, out_features=1408, bias=False)\n",
              "              (up_proj): Linear(in_features=2048, out_features=1408, bias=False)\n",
              "              (down_proj): Linear(in_features=1408, out_features=2048, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "          )\n",
              "          (shared_expert): Qwen2MoeMLP(\n",
              "            (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
              "            (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
              "            (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
              "            (act_fn): SiLU()\n",
              "          )\n",
              "          (shared_expert_gate): Linear(in_features=2048, out_features=1, bias=False)\n",
              "        )\n",
              "        (input_layernorm): Qwen2MoeRMSNorm((2048,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen2MoeRMSNorm((2048,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen2MoeRMSNorm((2048,), eps=1e-06)\n",
              "    (rotary_emb): Qwen2MoeRotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FB_-JouaUkbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "adapter_dir = \"/content/drive/MyDrive/AdaptersMoE\"\n",
        "os.makedirs(adapter_dir, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "4PAMaU6LH4Tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Colab-Ready Notebook: Functional Similarity Testing for MoE Experts (Decoder-Only)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from collections import defaultdict\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "\n",
        "layer1 = 1\n",
        "layer2 = 2\n",
        "num_experts = len(model.model.layers[layer1].mlp.experts)\n",
        "results = []\n",
        "\n",
        "selected_experts = [0, 1, 2, 3, 4, 5, 6, 7]  # any 8 unique IDs from 0–59\n",
        "\n",
        "for eid1 in selected_experts:\n",
        "    for eid2 in selected_experts:\n",
        "\n",
        "# for eid1 in range(num_experts):\n",
        "#     for eid2 in range(num_experts):\n",
        "        if (layer2, eid2, layer1, eid1) in [(l2, e2, l1, e1) for (l1, e1, l2, e2, *_ ) in results]:\n",
        "            continue\n",
        "\n",
        "        print(f\"Analyzing: Layer {layer1} Expert {eid1} ↔ Layer {layer2} Expert {eid2}\")\n",
        "        expert_pairs.clear()\n",
        "        layer_inputs.clear()\n",
        "        hooks = attach_moe_hooks(model, (layer1, eid1), (layer2, eid2))\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in train_loader:\n",
        "                input_ids = torch.stack(batch['input_ids']).to('cuda')\n",
        "                model(input_ids)\n",
        "                if len(expert_pairs[(layer1, eid1)]) >= 5000:\n",
        "                    break\n",
        "\n",
        "        for h in hooks: h.remove()\n",
        "\n",
        "        try:\n",
        "            z1, f1_out = get_aligned_data(layer1, eid1, model.device)\n",
        "            f2 = model.model.layers[layer2].mlp.experts[eid2]\n",
        "            adapter, loss = train_adapter_aligning_experts(z1, f1_out, f2)\n",
        "            results.append((layer1, eid1, layer2, eid2, loss))\n",
        "\n",
        "            # Save adapter\n",
        "            fname = f\"{adapter_dir}/adapter_L{layer1}E{eid1}_to_L{layer2}E{eid2}.pt\"\n",
        "            torch.save(adapter.state_dict(), fname)\n",
        "            print(f\"✅ Saved: {fname} | Loss: {loss:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Skipped pair ({layer1},{eid1}) → ({layer2},{eid2}) due to error: {e}\")\n",
        "\n",
        "\n",
        "# -------------------\n",
        "# Result Table\n",
        "# -------------------\n",
        "print(\"\\n\\n====== Functional Similarity Table (MSE Loss) ======\")\n",
        "df = pd.DataFrame(\"-\", index=[f\"E{eid1}\" for eid1 in range(num_experts)], columns=[f\"E{eid2}\" for eid2 in range(num_experts)])\n",
        "for _, eid1, _, eid2, loss in results:\n",
        "    df.loc[f\"E{eid1}\", f\"E{eid2}\"] = f\"{loss:.4f}\"\n",
        "\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2ltfvpY04wLC",
        "outputId": "878a07d2-5ed3-4868-e161-eb670285a5b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing: Layer 1 Expert 0 ↔ Layer 2 Expert 0\n",
            "9.779531478881836\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E0_to_L2E0.pt | Loss: 9.7795\n",
            "Analyzing: Layer 1 Expert 0 ↔ Layer 2 Expert 1\n",
            "6.640830993652344\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E0_to_L2E1.pt | Loss: 6.6408\n",
            "Analyzing: Layer 1 Expert 0 ↔ Layer 2 Expert 2\n",
            "6.242130756378174\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E0_to_L2E2.pt | Loss: 6.2421\n",
            "Analyzing: Layer 1 Expert 0 ↔ Layer 2 Expert 3\n",
            "7.418803691864014\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E0_to_L2E3.pt | Loss: 7.4188\n",
            "Analyzing: Layer 1 Expert 0 ↔ Layer 2 Expert 4\n",
            "7.009343147277832\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E0_to_L2E4.pt | Loss: 7.0093\n",
            "Analyzing: Layer 1 Expert 0 ↔ Layer 2 Expert 5\n",
            "6.691318511962891\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E0_to_L2E5.pt | Loss: 6.6913\n",
            "Analyzing: Layer 1 Expert 0 ↔ Layer 2 Expert 6\n",
            "5.898207664489746\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E0_to_L2E6.pt | Loss: 5.8982\n",
            "Analyzing: Layer 1 Expert 0 ↔ Layer 2 Expert 7\n",
            "6.056107997894287\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E0_to_L2E7.pt | Loss: 6.0561\n",
            "Analyzing: Layer 1 Expert 1 ↔ Layer 2 Expert 0\n",
            "0.011413836851716042\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E1_to_L2E0.pt | Loss: 0.0114\n",
            "Analyzing: Layer 1 Expert 1 ↔ Layer 2 Expert 1\n",
            "0.006325600203126669\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E1_to_L2E1.pt | Loss: 0.0063\n",
            "Analyzing: Layer 1 Expert 1 ↔ Layer 2 Expert 2\n",
            "0.007009434048086405\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E1_to_L2E2.pt | Loss: 0.0070\n",
            "Analyzing: Layer 1 Expert 1 ↔ Layer 2 Expert 3\n",
            "0.006300799082964659\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E1_to_L2E3.pt | Loss: 0.0063\n",
            "Analyzing: Layer 1 Expert 1 ↔ Layer 2 Expert 4\n",
            "0.00619085319340229\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E1_to_L2E4.pt | Loss: 0.0062\n",
            "Analyzing: Layer 1 Expert 1 ↔ Layer 2 Expert 5\n",
            "0.006613441742956638\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E1_to_L2E5.pt | Loss: 0.0066\n",
            "Analyzing: Layer 1 Expert 1 ↔ Layer 2 Expert 6\n",
            "0.006716444157063961\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E1_to_L2E6.pt | Loss: 0.0067\n",
            "Analyzing: Layer 1 Expert 1 ↔ Layer 2 Expert 7\n",
            "0.006406829692423344\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E1_to_L2E7.pt | Loss: 0.0064\n",
            "Analyzing: Layer 1 Expert 2 ↔ Layer 2 Expert 0\n",
            "0.009961407631635666\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E2_to_L2E0.pt | Loss: 0.0100\n",
            "Analyzing: Layer 1 Expert 2 ↔ Layer 2 Expert 1\n",
            "0.006930923089385033\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E2_to_L2E1.pt | Loss: 0.0069\n",
            "Analyzing: Layer 1 Expert 2 ↔ Layer 2 Expert 2\n",
            "0.007285370025783777\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E2_to_L2E2.pt | Loss: 0.0073\n",
            "Analyzing: Layer 1 Expert 2 ↔ Layer 2 Expert 3\n",
            "0.006775480229407549\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E2_to_L2E3.pt | Loss: 0.0068\n",
            "Analyzing: Layer 1 Expert 2 ↔ Layer 2 Expert 4\n",
            "0.006602361332625151\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E2_to_L2E4.pt | Loss: 0.0066\n",
            "Analyzing: Layer 1 Expert 2 ↔ Layer 2 Expert 5\n",
            "0.006886032875627279\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E2_to_L2E5.pt | Loss: 0.0069\n",
            "Analyzing: Layer 1 Expert 2 ↔ Layer 2 Expert 6\n",
            "0.007210869807749987\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E2_to_L2E6.pt | Loss: 0.0072\n",
            "Analyzing: Layer 1 Expert 2 ↔ Layer 2 Expert 7\n",
            "0.006923274137079716\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E2_to_L2E7.pt | Loss: 0.0069\n",
            "Analyzing: Layer 1 Expert 3 ↔ Layer 2 Expert 0\n",
            "0.009699066169559956\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E3_to_L2E0.pt | Loss: 0.0097\n",
            "Analyzing: Layer 1 Expert 3 ↔ Layer 2 Expert 1\n",
            "0.006191267166286707\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E3_to_L2E1.pt | Loss: 0.0062\n",
            "Analyzing: Layer 1 Expert 3 ↔ Layer 2 Expert 2\n",
            "0.007035454735159874\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E3_to_L2E2.pt | Loss: 0.0070\n",
            "Analyzing: Layer 1 Expert 3 ↔ Layer 2 Expert 3\n",
            "0.005975027568638325\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E3_to_L2E3.pt | Loss: 0.0060\n",
            "Analyzing: Layer 1 Expert 3 ↔ Layer 2 Expert 4\n",
            "0.006325083784759045\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E3_to_L2E4.pt | Loss: 0.0063\n",
            "Analyzing: Layer 1 Expert 3 ↔ Layer 2 Expert 5\n",
            "0.006579016335308552\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E3_to_L2E5.pt | Loss: 0.0066\n",
            "Analyzing: Layer 1 Expert 3 ↔ Layer 2 Expert 6\n",
            "0.006754077039659023\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E3_to_L2E6.pt | Loss: 0.0068\n",
            "Analyzing: Layer 1 Expert 3 ↔ Layer 2 Expert 7\n",
            "0.006441792473196983\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E3_to_L2E7.pt | Loss: 0.0064\n",
            "Analyzing: Layer 1 Expert 4 ↔ Layer 2 Expert 0\n",
            "0.01068479847162962\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E4_to_L2E0.pt | Loss: 0.0107\n",
            "Analyzing: Layer 1 Expert 4 ↔ Layer 2 Expert 1\n",
            "0.006030965596437454\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E4_to_L2E1.pt | Loss: 0.0060\n",
            "Analyzing: Layer 1 Expert 4 ↔ Layer 2 Expert 2\n",
            "0.006470797583460808\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E4_to_L2E2.pt | Loss: 0.0065\n",
            "Analyzing: Layer 1 Expert 4 ↔ Layer 2 Expert 3\n",
            "0.006223906297236681\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E4_to_L2E3.pt | Loss: 0.0062\n",
            "Analyzing: Layer 1 Expert 4 ↔ Layer 2 Expert 4\n",
            "0.006047934293746948\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E4_to_L2E4.pt | Loss: 0.0060\n",
            "Analyzing: Layer 1 Expert 4 ↔ Layer 2 Expert 5\n",
            "0.006481778807938099\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E4_to_L2E5.pt | Loss: 0.0065\n",
            "Analyzing: Layer 1 Expert 4 ↔ Layer 2 Expert 6\n",
            "0.006620804313570261\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E4_to_L2E6.pt | Loss: 0.0066\n",
            "Analyzing: Layer 1 Expert 4 ↔ Layer 2 Expert 7\n",
            "0.0061116768047213554\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E4_to_L2E7.pt | Loss: 0.0061\n",
            "Analyzing: Layer 1 Expert 5 ↔ Layer 2 Expert 0\n",
            "0.006415650248527527\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E5_to_L2E0.pt | Loss: 0.0064\n",
            "Analyzing: Layer 1 Expert 5 ↔ Layer 2 Expert 1\n",
            "0.00460907444357872\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E5_to_L2E1.pt | Loss: 0.0046\n",
            "Analyzing: Layer 1 Expert 5 ↔ Layer 2 Expert 2\n",
            "0.0049864077009260654\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E5_to_L2E2.pt | Loss: 0.0050\n",
            "Analyzing: Layer 1 Expert 5 ↔ Layer 2 Expert 3\n",
            "0.004640312399715185\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E5_to_L2E3.pt | Loss: 0.0046\n",
            "Analyzing: Layer 1 Expert 5 ↔ Layer 2 Expert 4\n",
            "0.00455591781064868\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E5_to_L2E4.pt | Loss: 0.0046\n",
            "Analyzing: Layer 1 Expert 5 ↔ Layer 2 Expert 5\n",
            "0.004819217137992382\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E5_to_L2E5.pt | Loss: 0.0048\n",
            "Analyzing: Layer 1 Expert 5 ↔ Layer 2 Expert 6\n",
            "0.004959906917065382\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E5_to_L2E6.pt | Loss: 0.0050\n",
            "Analyzing: Layer 1 Expert 5 ↔ Layer 2 Expert 7\n",
            "0.0048529659397900105\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E5_to_L2E7.pt | Loss: 0.0049\n",
            "Analyzing: Layer 1 Expert 6 ↔ Layer 2 Expert 0\n",
            "0.008802134543657303\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E6_to_L2E0.pt | Loss: 0.0088\n",
            "Analyzing: Layer 1 Expert 6 ↔ Layer 2 Expert 1\n",
            "0.005538324825465679\n",
            "✅ Saved: /content/drive/MyDrive/AdaptersMoE/adapter_L1E6_to_L2E1.pt | Loss: 0.0055\n",
            "Analyzing: Layer 1 Expert 6 ↔ Layer 2 Expert 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-16-2797085562>\", line 34, in <cell line: 0>\n",
            "    model(input_ids)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\", line 969, in wrapper\n",
            "    output = func(self, *args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py\", line 1161, in forward\n",
            "    outputs: MoeModelOutputWithPast = self.model(\n",
            "                                      ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\", line 969, in wrapper\n",
            "    output = func(self, *args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py\", line 877, in forward\n",
            "    layer_outputs = decoder_layer(\n",
            "                    ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py\", line 713, in forward\n",
            "    hidden_states = self.mlp(hidden_states)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py\", line 622, in forward\n",
            "    current_hidden_states = expert_layer(current_state) * routing_weights[top_x, idx, None]\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py\", line 247, in forward\n",
            "    return self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1735, in _wrapped_call_impl\n",
            "    def _wrapped_call_impl(self, *args, **kwargs):\n",
            "    \n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1688, in getframeinfo\n",
            "    lines, lnum = findsource(frame)\n",
            "                  ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 170, in findsource\n",
            "    file = getsourcefile(object) or getfile(object)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 948, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 988, in getmodule\n",
            "    if ismodule(module) and hasattr(module, '__file__'):\n",
            "       ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 283, in ismodule\n",
            "    def ismodule(object):\n",
            "    \n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-2797085562>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpert_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meid1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_requested_to_return_tuple\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_configured_to_return_tuple\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_top_level_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, output_router_logits, cache_position, logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m         outputs: MoeModelOutputWithPast = self.model(\n\u001b[0m\u001b[1;32m   1162\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_requested_to_return_tuple\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_configured_to_return_tuple\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_top_level_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, output_router_logits, cache_position)\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    878\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, output_router_logits, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0mcurrent_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m             \u001b[0mcurrent_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrouting_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_wrapped_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1736\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z2_all = []\n",
        "\n",
        "def make_aligned_expert_hook(layer_id, expert_id):\n",
        "    def hook_fn(module, input, output):\n",
        "        z = input[0].detach().cpu()\n",
        "        fz = output.detach().cpu()\n",
        "        for i in range(z.shape[0]):\n",
        "            expert_pairs[(layer_id, expert_id)].append((z[i], fz[i]))\n",
        "        if layer_id == layer2:\n",
        "            z2_all.append(z)\n",
        "    return hook_fn\n",
        "\n"
      ],
      "metadata": {
        "id": "AEJWZVr9PSUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z2 = torch.cat(z2_all, dim=0).to(model.device)\n"
      ],
      "metadata": {
        "id": "QWWXdTu5PZgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "Ig5TL8jsRcWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_distribution_stats(z1, y1, z2):\n",
        "    \"\"\"Visualize the raw value distributions of z1, y1, and z2 using histograms.\"\"\"\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    for idx, (data, label) in enumerate(zip([z1, y1, z2], ['z1 (input L1)', 'y1 (output L1)', 'z2 (input L2)'])):\n",
        "        plt.subplot(1, 3, idx+1)\n",
        "        flattened = data.detach().cpu().numpy().flatten()\n",
        "        plt.hist(flattened, bins=100, alpha=0.7, color='C' + str(idx))\n",
        "        plt.title(f\"{label}\\nMean: {flattened.mean():.4f}, Std: {flattened.std():.4f}\")\n",
        "        plt.grid(True)\n",
        "\n",
        "    plt.suptitle(\"Distribution of Activation Values\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "rPZlNKa6HrGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_pca_distributions(z1, y1, z2):\n",
        "    pca = PCA(n_components=2)\n",
        "    all_data = torch.cat([z1, y1, z2], dim=0).cpu().numpy()\n",
        "    reduced = pca.fit_transform(all_data)\n",
        "    n = z1.size(0)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(reduced[:n, 0], reduced[:n, 1], label=\"z1 (Input Layer 1)\", alpha=0.5)\n",
        "    plt.scatter(reduced[n:2*n, 0], reduced[n:2*n, 1], label=\"y1 (Output Layer 1)\", alpha=0.5)\n",
        "    plt.scatter(reduced[2*n:, 0], reduced[2*n:, 1], label=\"z2 (Input Layer 2)\", alpha=0.5)\n",
        "    plt.legend()\n",
        "    plt.title(\"PCA of z1, y1, z2\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Ux83HdRRRbfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def attach_all_hooks(model, layer1, layer2, expert_ids):\n",
        "    hooks = []\n",
        "    for lid in [layer1, layer2]:\n",
        "\n",
        "        moe_block = model.model.layers[lid].mlp\n",
        "        hooks.append(moe_block.register_forward_pre_hook(make_router_input_hook(lid)))\n",
        "        for eid in expert_ids:\n",
        "            expert = moe_block.experts[eid]\n",
        "            hooks.append(expert.register_forward_hook(make_aligned_expert_hook(lid, eid)))\n",
        "    return hooks"
      ],
      "metadata": {
        "id": "Le05uOEk7vAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# selected_experts = [0, 4, 8, 12, 16, 20, 24, 28]\n",
        "selected_experts = [1, 15, 20, 25, 45, 59]"
      ],
      "metadata": {
        "id": "az_L4RtU8xNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for h in hooks:\n",
        "  h.remove()"
      ],
      "metadata": {
        "id": "dTyUjksONBPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer1 = 1\n",
        "layer2 = 20\n",
        "hooks = attach_all_hooks(model, layer1, layer2, selected_experts)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in train_loader:\n",
        "        input_ids = torch.stack(batch['input_ids']).to(model.device)\n",
        "        model(input_ids)\n",
        "        # You can optionally stop early\n",
        "        if all(len(expert_pairs[(layer1, eid)]) >= 100 for eid in selected_experts):\n",
        "            break\n",
        "        else:\n",
        "          print(len(expert_pairs[(layer1, eid)]) for eid in selected_experts)\n",
        "\n",
        "for h in hooks: h.remove()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "dBiX2PSn7xrk",
        "outputId": "56960fc1-2e20-4ac9-b983-6f50763a8518",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object <genexpr> at 0x7f4ab0c47c40>\n",
            "<generator object <genexpr> at 0x7f4ab0c47c40>\n",
            "<generator object <genexpr> at 0x7f4ab0c47c40>\n",
            "<generator object <genexpr> at 0x7f4ab0c47c40>\n",
            "<generator object <genexpr> at 0x7f4ab0c47c40>\n",
            "<generator object <genexpr> at 0x7f4ab0c47c40>\n",
            "<generator object <genexpr> at 0x7f4ab0c47c40>\n",
            "<generator object <genexpr> at 0x7f4ab0c47c40>\n",
            "<generator object <genexpr> at 0x7f4ab0c47c40>\n",
            "<generator object <genexpr> at 0x7f4ab0c47c40>\n",
            "<generator object <genexpr> at 0x7f4ab0c47c40>\n",
            "<generator object <genexpr> at 0x7f4ab0c47c40>\n",
            "<generator object <genexpr> at 0x7f4ab0c47c40>\n",
            "<generator object <genexpr> at 0x7f4ab0c47c40>\n",
            "<generator object <genexpr> at 0x7f4ab0c47c40>\n",
            "<generator object <genexpr> at 0x7f4ab0c47c40>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-1723626513>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m# You can optionally stop early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpert_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected_experts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_requested_to_return_tuple\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_configured_to_return_tuple\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_top_level_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, output_router_logits, cache_position, logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m         outputs: MoeModelOutputWithPast = self.model(\n\u001b[0m\u001b[1;32m   1162\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_requested_to_return_tuple\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_configured_to_return_tuple\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_top_level_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, output_router_logits, cache_position)\u001b[0m\n\u001b[1;32m    875\u001b[0m                 )\n\u001b[1;32m    876\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    878\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, output_router_logits, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrouter_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    626\u001b[0m             \u001b[0mfinal_hidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_hidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m         \u001b[0mshared_expert_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared_expert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m         \u001b[0mshared_expert_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared_expert_gate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mshared_expert_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "adapter_dir = \"/content/drive/MyDrive/AdaptersMoE\"\n",
        "os.makedirs(adapter_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "B5ODpbl3DeUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for eid1 in selected_experts:\n",
        "    for eid2 in selected_experts:\n",
        "        if (layer2, eid2, layer1, eid1) in [(l2, e2, l1, e1) for (l1, e1, l2, e2, *_ ) in results]:\n",
        "            continue\n",
        "        try:\n",
        "            z1, f1_out = get_aligned_data(layer1, eid1, model.device, max_samples=200)\n",
        "            f2 = model.model.layers[layer2].mlp.experts[eid2]\n",
        "            adapter, loss = train_adapter_aligning_experts(z1, f1_out, f2)\n",
        "            results.append((layer1, eid1, layer2, eid2, loss))\n",
        "            # Save adapter\n",
        "            fname = f\"{adapter_dir}/adapter_L{layer1}E{eid1}_to_L{layer2}E{eid2}.pt\"\n",
        "            torch.save(adapter.state_dict(), fname)\n",
        "            print(f\"✅ Saved: {fname} | Loss: {loss:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Failed: ({eid1} → {eid2}) - {e}\")\n"
      ],
      "metadata": {
        "id": "F_SfzSED72PZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EaPQAU6eepDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()"
      ],
      "metadata": {
        "id": "aNNqeh3YE-Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del train_loader"
      ],
      "metadata": {
        "id": "WYdcL-XiDtGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v0PBAU5GAHdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(expert_pairs[(1, 0)]))\n",
        "print(len(expert_pairs[(1, 30)]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMnl53sCeFZo",
        "outputId": "3a33fe37-6457-45f7-f25b-590d06bad6d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1908\n",
            "188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JjsT2TXteFzS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}